{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe993bb5",
   "metadata": {},
   "source": [
    "# ML models \n",
    "---- \n",
    "\n",
    "# Performance Evaluation methods\n",
    "----\n",
    "\n",
    "# Feature Selection Methods\n",
    "\n",
    "## 1. Filter Methods\n",
    "\n",
    "### 1.1 Parametric Methods (Univariants)\n",
    "\n",
    "#### Discrete Predictors\n",
    "- Mutual information  \n",
    "- Gain ratio  \n",
    "- Symmetrical uncertainty  \n",
    "- Chi-squared  \n",
    "- Odds ratio  \n",
    "- Bi-normal separation  \n",
    "\n",
    "#### Continuous Predictors\n",
    "- t-test family  \n",
    "- ANOVA  \n",
    "\n",
    "### 1.2 Model-Free Methods (Univariants)\n",
    "- Threshold number of misclassification (TNoM)  \n",
    "- P-metric  \n",
    "- Mann-Whitney test  \n",
    "- Kruskal-Wallis test  \n",
    "- Between-groups to within-groups sum of squares  \n",
    "- Scores based on estimating density functions  \n",
    "\n",
    "\n",
    "### 1.3 Multivariant\n",
    "\n",
    "- RELIEF algorithm\n",
    "- Correlation-based feature selection\n",
    "- Conditional mutual information\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Wrapper Methods\n",
    "\n",
    "### 2.1 Deterministic Heuristics\n",
    "\n",
    "#### Sequential Methods\n",
    "- Sequential feature selection  \n",
    "- Sequential forward feature selection  \n",
    "- Sequential backward elimination  \n",
    "\n",
    "#### Greedy and Best-First Approaches\n",
    "- Greedy hill climbing  \n",
    "- Best first  \n",
    "\n",
    "#### Hybrid and Adaptive Methods\n",
    "- Plus-L-Minus-r algorithm  \n",
    "- Floating search selection  \n",
    "\n",
    "#### Advanced Deterministic Search\n",
    "- Tabu search  \n",
    "- Branch and bound  \n",
    "\n",
    "### 2.2 Non-Deterministic Heuristics\n",
    "\n",
    "#### Single-Solution Metaheuristics\n",
    "- Simulated annealing  \n",
    "- Las Vegas algorithm  \n",
    "- Greedy randomized adaptive search procedure (GRASP)  \n",
    "- Variable neighborhood search  \n",
    "\n",
    "#### Population-Based Metaheuristics\n",
    "- Scatter search  \n",
    "- Ant colony optimization  \n",
    "- Particle swarm optimization  \n",
    "\n",
    "#### Evolutionary Algorithms\n",
    "- Genetic algorithms  \n",
    "- Estimation of distribution algorithms  \n",
    "- Differential evolution  \n",
    "- Genetic programming  \n",
    "- Evolution strategies\n",
    "\n",
    "----\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c968ef3b",
   "metadata": {},
   "source": [
    "Tipo\tEvaluadores\n",
    "\n",
    "-Filtro univariante: \tInfoGainAttributeEval, GainRatioAttributeEval, SymmetricalUncertAttributeEval, OneRAttributeEval, CorrelationAttributeEval, ReliefFAttributeEval\n",
    "\n",
    "-Filtro multivariante:     CfsSubsetEval, PrincipalComponents\n",
    "\n",
    "-Wrapper:   \tWrapperSubsetEval, ClassifierSubsetEval, ClassifierAttributeEval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1dcbe99",
   "metadata": {},
   "source": [
    "# WEKA ‚Äî Classification Models (Supervised Learning)\n",
    "\n",
    "Gu√≠a completa de clasificadores de **WEKA** organizada por tipo de modelo y naturaleza estad√≠stica.  \n",
    "Incluye las rutas de clase (`weka.classifiers...`) para su uso en **Experimenter** o **CLI**.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚öôÔ∏è Non-Probabilistic Models\n",
    "\n",
    "### üîπ KNN (K-Nearest Neighbors)\n",
    "| Tipo general | Nombre en WEKA | Ruta / Clase | Tipo | Naturaleza del modelo |\n",
    "|---------------|----------------|---------------|-------|------------------------|\n",
    "| KNN cl√°sico | **IBk** | `weka.classifiers.lazy.IBk` | No param√©trico | Basado en distancias (vecindad) |\n",
    "| K* (versi√≥n basada en entrop√≠a) | **KStar** | `weka.classifiers.lazy.KStar` | No param√©trico | Basado en entrop√≠a y similitud probabil√≠stica |\n",
    "| LWL (Locally Weighted Learning, variante ponderada) | **LWL** | `weka.classifiers.lazy.LWL` | No param√©trico | Basado en distancias ponderadas localmente |\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Rule Induction (Inducci√≥n de Reglas)\n",
    "| Tipo general | Nombre en WEKA | Ruta / Clase | Tipo | Naturaleza del modelo |\n",
    "|---------------|----------------|---------------|-------|------------------------|\n",
    "| Reglas tipo RIPPER | **JRip** | `weka.classifiers.rules.JRip` | No param√©trico | Basado en reglas l√≥gicas (IF-THEN) |\n",
    "| Reglas OneR (una regla por atributo) | **OneR** | `weka.classifiers.rules.OneR` | No param√©trico | Basado en reglas simples por atributo |\n",
    "| Reglas PART (a partir de √°rboles) | **PART** | `weka.classifiers.rules.PART` | No param√©trico | Basado en reglas derivadas de √°rboles |\n",
    "| Decision Table | **DecisionTable** | `weka.classifiers.rules.DecisionTable` | No param√©trico | Basado en tabla de decisiones (combinaciones de atributos) |\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ ANN (Artificial Neural Networks)\n",
    "| Tipo general | Nombre en WEKA | Ruta / Clase | Tipo | Naturaleza del modelo |\n",
    "|---------------|----------------|---------------|-------|------------------------|\n",
    "| Multilayer Perceptron (MLP cl√°sico, backpropagation) | **MultilayerPerceptron** | `weka.classifiers.functions.MultilayerPerceptron` | Param√©trico | No lineal, basado en capas neuronales |\n",
    "| Red de base radial | **RBFNetwork** | `weka.classifiers.functions.RBFNetwork` | Param√©trico | No lineal, funciones de base radial |\n",
    "| Variante moderna de RBF | **RBFClassifier** | `weka.classifiers.functions.RBFClassifier` | Param√©trico | No lineal, funciones de base radial |\n",
    "| Simple Logistic (una capa log√≠stica, con boosting) | **SimpleLogistic** | `weka.classifiers.functions.SimpleLogistic` | Param√©trico | Lineal (regresi√≥n log√≠stica con boosting) |\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ SVM (Support Vector Machines)\n",
    "| Tipo general | Nombre en WEKA | Ruta / Clase | Tipo | Naturaleza del modelo |\n",
    "|---------------|----------------|---------------|-------|------------------------|\n",
    "| SVM cl√°sico (SMO = Sequential Minimal Optimization) | **SMO** | `weka.classifiers.functions.SMO` | Param√©trico | Lineal o no lineal (seg√∫n kernel) |\n",
    "| SVM con regresi√≥n (para tareas de regresi√≥n) | **SMOreg** | `weka.classifiers.functions.SMOreg` | Param√©trico | Lineal o no lineal (seg√∫n kernel) |\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ √Årboles de Decisi√≥n\n",
    "| Tipo general | Nombre en WEKA | Ruta / Clase | Tipo | Naturaleza del modelo |\n",
    "|---------------|----------------|---------------|-------|------------------------|\n",
    "| ID3 (b√°sico, sin pruning) | **Id3** | `weka.classifiers.trees.Id3` | No param√©trico | Basado en particiones de entrop√≠a (no lineal) |\n",
    "| C4.5 (implementaci√≥n mejorada: J48) | **J48** | `weka.classifiers.trees.J48` | No param√©trico | Basado en ganancia de informaci√≥n (no lineal) |\n",
    "| Random Tree | **RandomTree** | `weka.classifiers.trees.RandomTree` | No param√©trico | Basado en √°rboles aleatorios (no lineal) |\n",
    "| Random Forest | **RandomForest** | `weka.classifiers.trees.RandomForest` | No param√©trico | Ensamble de √°rboles, no lineal |\n",
    "| REPTree (similar a CART) | **REPTree** | `weka.classifiers.trees.REPTree` | No param√©trico | Basado en reducci√≥n de error, no lineal |\n",
    "| Decision Stump (un solo nodo, √∫til para boosting) | **DecisionStump** | `weka.classifiers.trees.DecisionStump` | No param√©trico | Lineal por tramos (una divisi√≥n) |\n",
    "| Logistic Model Tree | **LMT** | `weka.classifiers.trees.LMT` | H√≠brido | No lineal (√°rbol con regresi√≥n log√≠stica en hojas) |\n",
    "\n",
    "---\n",
    "\n",
    "## üé≤ Probabilistic Models\n",
    "\n",
    "### üîπ Bayesian ‚Äî Discrete\n",
    "| Tipo general | Nombre en WEKA | Ruta / Clase | Tipo | Naturaleza del modelo |\n",
    "|---------------|----------------|---------------|-------|------------------------|\n",
    "| Naive Bayes cl√°sico (atributos discretos) | **NaiveBayes** | `weka.classifiers.bayes.NaiveBayes` | Param√©trico | Probabil√≠stico cl√°sico basado en independencia condicional |\n",
    "| Naive Bayes Multinomial | **NaiveBayesMultinomial** | `weka.classifiers.bayes.NaiveBayesMultinomial` | Param√©trico | Para datos de texto o conteo (multinomial) |\n",
    "| Complement Naive Bayes | **ComplementNB** | `weka.classifiers.bayes.ComplementNB` | Param√©trico | Variante robusta para clases desbalanceadas |\n",
    "| Hidden Naive Bayes | **HNB** | `weka.classifiers.bayes.HNB` | Param√©trico | Extiende NB considerando dependencias entre atributos |\n",
    "| Bayesian Network | **BayesNet** | `weka.classifiers.bayes.BayesNet` | Param√©trico | Modela relaciones de dependencia entre variables (grafo ac√≠clico) |\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Bayesian ‚Äî Continuous\n",
    "| Tipo general | Nombre en WEKA | Ruta / Clase | Tipo | Naturaleza del modelo |\n",
    "|---------------|----------------|---------------|-------|------------------------|\n",
    "| Naive Bayes para atributos continuos (asume normalidad) | **NaiveBayesSimple** | `weka.classifiers.bayes.NaiveBayesSimple` | Param√©trico | Supone distribuci√≥n gaussiana de los atributos |\n",
    "| Naive Bayes con estimaci√≥n Kernel | **NaiveBayesKDE** | `weka.classifiers.bayes.NaiveBayesKDE` | Param√©trico | Estima densidades continuas mediante kernel |\n",
    "| Naive Bayes KNN (versi√≥n mixta) | **NaiveBayesKNN** | `weka.classifiers.bayes.NaiveBayesKNN` | Param√©trico | Estima densidad con vecinos m√°s cercanos |\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Logistic / Probabilistic Regression\n",
    "| Tipo general | Nombre en WEKA | Ruta / Clase | Tipo | Naturaleza del modelo |\n",
    "|---------------|----------------|---------------|-------|------------------------|\n",
    "| Regresi√≥n log√≠stica | **Logistic** | `weka.classifiers.functions.Logistic` | Param√©trico | Estima probabilidad con funci√≥n log√≠stica (sigmoide) |\n",
    "| Simple Logistic (con boosting) | **SimpleLogistic** | `weka.classifiers.functions.SimpleLogistic` | Param√©trico | Ensamble de regresiones log√≠sticas simples |\n",
    "| Linear Regression (para clasificaci√≥n softmax) | **LinearRegression** | `weka.classifiers.functions.LinearRegression` | Param√©trico | Lineal, adaptable a clasificaci√≥n binaria probabil√≠stica |\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Discriminant Analysis\n",
    "| Tipo general | Nombre en WEKA | Ruta / Clase | Tipo | Naturaleza del modelo |\n",
    "|---------------|----------------|---------------|-------|------------------------|\n",
    "| Linear Discriminant Analysis | **LinearDiscriminantAnalysis (LDA)** | `weka.classifiers.functions.LinearDiscriminantAnalysis` *(paquete externo)* | Param√©trico | Probabil√≠stico lineal, asume covarianza igual entre clases |\n",
    "| Quadratic Discriminant Analysis | **QuadraticDiscriminantAnalysis (QDA)** | `weka.classifiers.functions.QuadraticDiscriminantAnalysis` *(paquete externo)* | Param√©trico | Probabil√≠stico cuadr√°tico, covarianzas distintas por clase |\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcca0c8a",
   "metadata": {},
   "source": [
    "# Gu√≠a de Par√°metros de Modelos para WEKA Experimenter\n",
    "\n",
    "Esta es una gu√≠a de los hiperpar√°metros m√°s importantes que puedes probar para los modelos listados en tu plan de an√°lisis.\n",
    "\n",
    "**Metodolog√≠a:** Para probar diferentes par√°metros de un mismo modelo (ej. RandomForest con 100 √°rboles y con 200 √°rboles), simplemente a√±ade RandomForest dos veces a la lista de \"Algorithms\" en el Experimenter y configura cada instancia con los par√°metros deseados.\n",
    "\n",
    "---\n",
    "\n",
    "## Experimento 1: Modelos Robustos (Grupo 1)\n",
    "\n",
    "**Dataset:** `datos_train_grupo1.arff`\n",
    "\n",
    "### √Årboles de Decisi√≥n\n",
    "\n",
    "**1. J48 (C4.5)**  \n",
    "- **confidenceFactor (-C):** Umbral para la poda.  \n",
    "  - Valores a probar: 0.1, 0.25 (default), 0.5  \n",
    "- **minNumObj (-M):** N√∫mero m√≠nimo de instancias por hoja.  \n",
    "  - Valores a probar: 2 (default), 5, 10  \n",
    "\n",
    "**2. Id3**  \n",
    "- No tiene par√°metros relevantes para tuning. Nota: tiende a sobreajustar.\n",
    "\n",
    "**3. RandomTree**  \n",
    "- **K (numFeatures):** N√∫mero de atributos a considerar aleatoriamente en cada divisi√≥n.  \n",
    "  - Valores a probar: 0 (default, usa log2(N)+1), 3, 5  \n",
    "- **maxDepth:** Profundidad m√°xima del √°rbol. 0 = sin l√≠mite.  \n",
    "  - Valores a probar: 0 (default), 5, 10  \n",
    "\n",
    "**4. RandomForest**  \n",
    "- **numIterations (-I):** N√∫mero de √°rboles en el bosque.  \n",
    "  - Valores a probar: 100 (default), 200, 500  \n",
    "- **maxDepth:** Profundidad m√°xima de cada √°rbol.  \n",
    "  - Valores a probar: 0 (default), 5, 10, 20  \n",
    "\n",
    "**5. REPTree**  \n",
    "- **minNum (-M):** M√≠nimo de instancias por hoja.  \n",
    "  - Valores a probar: 2.0 (default), 5.0, 10.0  \n",
    "- **maxDepth:** Profundidad m√°xima del √°rbol.  \n",
    "  - Valores a probar: -1 (default, sin l√≠mite), 3, 5  \n",
    "\n",
    "**6. DecisionStump**  \n",
    "- No tiene par√°metros. Nota: toma una sola decisi√≥n.\n",
    "\n",
    "**7. LMT (Logistic Model Tree)**  \n",
    "- **numBoostingIterations (-I):** Iteraciones de LogitBoost.  \n",
    "  - Valores a probar: -1 (default, auto), 10, 30  \n",
    "\n",
    "---\n",
    "\n",
    "### Inducci√≥n de Reglas\n",
    "\n",
    "**1. JRip (RIPPER)**  \n",
    "- **minNo (-N):** N√∫mero m√≠nimo de instancias que debe cubrir una regla.  \n",
    "  - Valores a probar: 2.0 (default), 3.0, 5.0  \n",
    "- **folds (-F):** N√∫mero de folds en la poda interna.  \n",
    "  - Valores a probar: 3 (default), 5  \n",
    "\n",
    "**2. OneR**  \n",
    "- **minBucketSize (-B):** M√≠nimo de instancias por cubeta.  \n",
    "  - Valores a probar: 6 (default), 10, 20  \n",
    "\n",
    "**3. PART**  \n",
    "- **confidenceFactor (-C):** Umbral de poda (igual que J48).  \n",
    "  - Valores a probar: 0.1, 0.25 (default), 0.5  \n",
    "- **minNumObj (-M):** M√≠nimo de instancias por hoja.  \n",
    "  - Valores a probar: 2 (default), 5, 10  \n",
    "\n",
    "**4. DecisionTable**  \n",
    "- **search:** Algoritmo para buscar el mejor subconjunto de atributos.  \n",
    "  - Valores a probar: BestFirst (default), GreedyStepwise  \n",
    "\n",
    "---\n",
    "\n",
    "## Experimento 2: Modelos Sensibles (Grupo 2)\n",
    "\n",
    "**Dataset:** `datos_train_grupo2.arff`  \n",
    "\n",
    "**Nota:** Aqu√≠ se usa `FilteredClassifier`. Hay dos niveles de par√°metros: del filtro (SMOTE) y del clasificador (SMO, IBk, etc.).\n",
    "\n",
    "### A. Par√°metros del Filtro (weka.filters.supervised.instance.SMOTE)\n",
    "\n",
    "- **percentage (-P):** Porcentaje de sobremuestreo.  \n",
    "  - Valores a probar: 100.0 (default), 300.0, 500.0  \n",
    "- **nearestNeighbors (-K):** Vecinos para generar instancias sint√©ticas.  \n",
    "  - Valores a probar: 5 (default), 3  \n",
    "\n",
    "---\n",
    "\n",
    "### B. Par√°metros de los Clasificadores\n",
    "\n",
    "**1. IBk (KNN)**  \n",
    "- **KNN (-K):** N√∫mero de vecinos.  \n",
    "  - Valores a probar: 1, 3, 5, 7, 11  \n",
    "\n",
    "**2. KStar**  \n",
    "- **globalBlend (-B):** Controla la esfera de influencia.  \n",
    "  - Valores a probar: 20 (default), 10, 40  \n",
    "\n",
    "**3. LWL (Locally Weighted Learning)**  \n",
    "- **KNN (-K):** Vecinos para ponderaci√≥n local.  \n",
    "  - Valores a probar: -1 (default, todos), 5, 10, 20  \n",
    "\n",
    "**4. MultilayerPerceptron (ANN)**  \n",
    "- **hiddenLayers (-H):** Arquitectura de la red.  \n",
    "  - Valores a probar: `'a'` (default), `'5'`, `'10,5'`  \n",
    "- **learningRate (-L):** Tasa de aprendizaje.  \n",
    "  - Valores a probar: 0.3 (default), 0.1, 0.01  \n",
    "- **trainingTime (-N):** √âpocas de entrenamiento.  \n",
    "  - Valores a probar: 500 (default), 1000, 2000  \n",
    "\n",
    "**5. RBFClassifier**  \n",
    "- **numClusters (-N):** N√∫mero de funciones de base radial.  \n",
    "  - Valores a probar: 2 (default), 5, 10, 20  \n",
    "\n",
    "**6. SimpleLogistic**  \n",
    "- **numBoostingIterations (-I):** Iteraciones de LogitBoost.  \n",
    "  - Valores a probar: 500 (default), 100, 1000  \n",
    "\n",
    "**7. SMO (SVM)**  \n",
    "- **C:** Regularizaci√≥n.  \n",
    "  - Valores a probar: 0.1, 1.0 (default), 10.0  \n",
    "- **kernel:** Funci√≥n de kernel.  \n",
    "  - Valores a probar:  \n",
    "    - `weka.classifiers.functions.supportVector.PolyKernel` (default)  \n",
    "    - `weka.classifiers.functions.supportVector.RBFKernel` (radial)  \n",
    "- **gamma (-G) (solo RBFKernel):** Influencia de un ejemplo.  \n",
    "  - Valores a probar: 0.01 (default), 0.1, 1.0  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7da22cc",
   "metadata": {},
   "source": [
    "# Gu√≠a de Par√°metros de Modelos Probabil√≠sticos para WEKA\n",
    "\n",
    "Esta es una gu√≠a de los hiperpar√°metros m√°s importantes que puedes probar para los modelos listados en tu plan de an√°lisis probabil√≠stico.\n",
    "\n",
    "---\n",
    "\n",
    "## Metodolog√≠a\n",
    "\n",
    "Para probar diferentes par√°metros de un mismo modelo (por ejemplo, BayesNet con TAN y BayesNet con K2), simplemente a√±ade BayesNet dos veces a la lista de *Algorithms* en el Experimenter y configura cada instancia con el `searchAlgorithm` deseado.\n",
    "\n",
    "---\n",
    "\n",
    "## Experimento 1: Modelos Robustos (Grupo 1)\n",
    "\n",
    "**Dataset:** `datos_train_grupo1.arff`  \n",
    "(Datos crudos, mixtos, sin anomal√≠as)\n",
    "\n",
    "### Modelos Bayesianos (Manejo Mixto)\n",
    "\n",
    "#### 1. NaiveBayes ‚Äî Tus modelos ‚ÄúMixtos‚Äù\n",
    "\n",
    "Aqu√≠ comparas c√≥mo tratar los predictores continuos.  \n",
    "A√±ade **NaiveBayes** dos veces:\n",
    "\n",
    "##### Prueba A: ‚ÄúKernel-Based‚Äù\n",
    "\n",
    "- **Par√°metro:** `useKernelEstimator (-K)` = `True`  \n",
    "- **Par√°metro:** `useSupervisedDiscretization (-D)` = `False`\n",
    "\n",
    "##### Prueba B: ‚ÄúDiscretized‚Äù\n",
    "\n",
    "- **Par√°metro:** `useKernelEstimator (-K)` = `False`  \n",
    "- **Par√°metro:** `useSupervisedDiscretization (-D)` = `True`\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. SelectiveNaiveBayes\n",
    "\n",
    "- **Par√°metro:** `search`  \n",
    "  - **Qu√© es:** M√©todo de b√∫squeda para seleccionar los atributos.  \n",
    "  - **Valores a probar:** `BestFirst (Default)`, `GreedyStepwise`\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. AODE (Averaged One-Dependence Estimators, relacionado con SP-ODE)\n",
    "\n",
    "- **Par√°metro:** `frequencyLimit (-f)`  \n",
    "  - **Qu√© es:** Frecuencia m√≠nima de un ‚Äúsuper-padre‚Äù para ser incluido.  \n",
    "  - **Valores a probar:** `1 (Default)`, `5`, `10`\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. KDB (k-dependence Bayesian Classifier)\n",
    "\n",
    "- **Par√°metro:** `k`  \n",
    "  - **Qu√© es:** Nivel de dependencia (el ‚Äúk‚Äù).  \n",
    "  - **Valores a probar:** `2`, `3`  \n",
    "  (Nota: `k=1` es equivalente a NaiveBayes).\n",
    "\n",
    "---\n",
    "\n",
    "#### 5. MarkovBlanketClassifier\n",
    "\n",
    "- **Par√°metro:** `search`  \n",
    "  - **Qu√© es:** Algoritmo para encontrar la ‚Äúmanta de Markov‚Äù de la clase.  \n",
    "  - **Valores a probar:** `BestFirst (Default)`, `GreedyStepwise`\n",
    "\n",
    "---\n",
    "\n",
    "#### 6. BayesNet ‚Äî Red Bayesiana General y TAN\n",
    "\n",
    "- **Par√°metro:** `searchAlgorithm`  \n",
    "  - **Qu√© es:** Algoritmo para aprender la estructura de la red.\n",
    "\n",
    "**Valores a probar** (a√±ade BayesNet 4 veces al experimento):\n",
    "\n",
    "| Variante | searchAlgorithm | Descripci√≥n |\n",
    "|-----------|----------------|--------------|\n",
    "| TAN | `weka.classifiers.bayes.net.search.local.TAN` | Tree Augmented Naive Bayes |\n",
    "| K2 | `weka.classifiers.bayes.net.search.local.K2` | R√°pido, requiere orden de atributos |\n",
    "| HillClimber | `weka.classifiers.bayes.net.search.local.HillClimber` | Clasificador no restringido |\n",
    "| TabuSearch | `weka.classifiers.bayes.net.search.local.TabuSearch` | Clasificador no restringido, m√°s lento y potente |\n",
    "\n",
    "---\n",
    "\n",
    "## Experimento 2: Modelos Sensibles (Grupo 2)\n",
    "\n",
    "**Dataset:** `datos_train_grupo2.arff`  \n",
    "(Datos 100% num√©ricos y normalizados)\n",
    "\n",
    "Nota: Aqu√≠ se usa **FilteredClassifier**.  \n",
    "Hay dos niveles de par√°metros: del filtro (**SMOTE**) y del clasificador (**Logistic**, **LDA**, etc.).\n",
    "\n",
    "---\n",
    "\n",
    "### A. Par√°metros del Filtro ‚Äî `weka.filters.supervised.instance.SMOTE`\n",
    "\n",
    "- **Par√°metro:** `percentage (-P)`  \n",
    "  - **Qu√© es:** Porcentaje de sobremuestreo.  \n",
    "  - **Valores a probar:** `100.0 (Default)`, `300.0`, `500.0` (depende del desbalanceo)\n",
    "\n",
    "- **Par√°metro:** `nearestNeighbors (-K)`  \n",
    "  - **Qu√© es:** N√∫mero de vecinos usados para generar instancias sint√©ticas.  \n",
    "  - **Valores a probar:** `5 (Default)`, `3`\n",
    "\n",
    "---\n",
    "\n",
    "### B. Par√°metros de los Clasificadores\n",
    "\n",
    "#### 1. Logistic ‚Äî Regresi√≥n Log√≠stica\n",
    "\n",
    "- **Par√°metro:** `ridge (-R)`  \n",
    "  - **Qu√© es:** Regularizaci√≥n L2 para prevenir sobreajuste.  \n",
    "  - **Valores a probar:** `1.0E-8 (Default)`, `0.01`, `0.1`, `1.0`\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. LinearDiscriminantAnalysis (LDA)\n",
    "\n",
    "- **Par√°metros:** (Pocos par√°metros relevantes para tuning)  \n",
    "  - **Nota:** El rendimiento de LDA depende casi exclusivamente del preprocesamiento  \n",
    "    (normalizaci√≥n, log-transformaciones, etc.) para cumplir el supuesto de normalidad.\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. QuadraticDiscriminantAnalysis (QDA)\n",
    "\n",
    "- **Par√°metros:** (Ninguno relevante para tuning)  \n",
    "  - **Nota:** Al igual que LDA, depende cr√≠ticamente de que los datos sigan una distribuci√≥n gaussiana.  \n",
    "    M√°s flexible que LDA al no asumir covarianza compartida.\n",
    "\n",
    "---\n",
    "\n",
    "## Resumen\n",
    "\n",
    "| Categor√≠a | Modelo | Par√°metro principal | Valores sugeridos |\n",
    "|------------|---------|--------------------|------------------|\n",
    "| Bayesianos mixtos | NaiveBayes | `-K`, `-D` | Kernel vs Discretization |\n",
    "| Selecci√≥n de atributos | SelectiveNaiveBayes | `search` | BestFirst / GreedyStepwise |\n",
    "| Dependencia promedio | AODE | `-f` | 1 / 5 / 10 |\n",
    "| Dependencia K | KDB | `k` | 2 / 3 |\n",
    "| Manta de Markov | MarkovBlanketClassifier | `search` | BestFirst / GreedyStepwise |\n",
    "| Redes Bayesianas | BayesNet | `searchAlgorithm` | TAN / K2 / HillClimber / TabuSearch |\n",
    "| Sobremuestreo | SMOTE | `-P`, `-K` | 100‚Äì500 / 3‚Äì5 |\n",
    "| Regresi√≥n log√≠stica | Logistic | `-R` | 1e-8 / 0.01 / 0.1 / 1.0 |\n",
    "| Discriminante | LDA / QDA | ‚Äî | Depende del preprocesamiento |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
