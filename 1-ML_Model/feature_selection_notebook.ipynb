{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Notebook de Selección de Características (Feature Selection)\n",
        "\n",
        "Este notebook implementa una variedad de técnicas de selección de características solicitadas, aplicadas al fichero `cleaned_main_financial_metrics.csv`.\n",
        "\n",
        "**Aviso Importante:** La lista proporcionada es extremadamente extensa y académica.\n",
        "* **Implementados:** Se implementarán los métodos más comunes y accesibles que se encuentran en las librerías estándar de Python (`scikit-learn`, `scipy`).\n",
        "* **No Implementados:** Muchos métodos (ej. Bi-normal separation, TNoM, GRASP, VNS, Scatter Search, ACO, PSO, Algoritmos de Estimación de Distribución, etc.) son muy especializados, no están en `scikit-learn` y requerirían implementaciones personalizadas complejas o librerías de nicho. Se dejará constancia de ellos.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0. Importar Librerías"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import warnings\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "# Filter Methods\n",
        "from sklearn.feature_selection import SelectKBest, f_classif, chi2, mutual_info_classif\n",
        "from scipy.stats import mannwhitneyu, kruskal\n",
        "\n",
        "# Wrapper Methods\n",
        "from sklearn.feature_selection import SequentialFeatureSelector\n",
        "from sklearn.metrics import accuracy_score, make_scorer\n",
        "\n",
        "# Models (Non-probabilistic)\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Carga y Preparación de Datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "5131bf84",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Clases del objetivo: [np.int64(0), np.int64(1), np.int64(2), np.int64(3), np.int64(4)]\n",
            "Características numéricas (47): ['numberOfAnalystOpinions', 'currentPrice', 'allTimeHigh', 'allTimeLow', '52WeekChange', 'fiftyDayAverageChangePercent', 'twoHundredDayAverageChangePercent', 'beta', 'averageVolume', 'marketCap', 'enterpriseValue', 'priceToBook', 'enterpriseToRevenue', 'profitMargins', 'grossMargins', 'ebitdaMargins', 'operatingMargins', 'returnOnAssets', 'returnOnEquity', 'revenueGrowth', 'totalRevenue', 'revenuePerShare', 'grossProfits', 'ebitda', 'netIncomeToCommon', 'trailingEps', 'totalCash', 'totalCashPerShare', 'totalDebt', 'quickRatio', 'currentRatio', 'bookValue', 'operatingCashflow', 'freeCashflow', 'trailingAnnualDividendYield', 'payoutRatio', 'sharesOutstanding', 'floatShares', 'sharesShort', 'sharesPercentSharesOut', 'shortRatio', 'shortPercentOfFloat', 'heldPercentInsiders', 'heldPercentInstitutions', 'fullTimeEmployees', '_debtToEquity', '_PER']\n",
            "Características categóricas (6): ['sector', 'state', 'In_SP500', 'In_NASDAQ', 'is_Insolvent', 'has_benefits']\n"
          ]
        }
      ],
      "source": [
        "# Preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler, OneHotEncoder\n",
        "\n",
        "\n",
        "TARGET_VARIABLE = 'recommendationClass'\n",
        "COLUMNS_TO_DROP = [\n",
        "    'recommendationKey', 'recommendationMean',\n",
        "    'shortName', 'symbol', 'Ticker', 'fullExchangeName', 'twoHundredDayAverage',\n",
        "]\n",
        "\n",
        "df = pd.read_csv('../cleaned_main_financial_metrics.csv')\n",
        "\n",
        "ALL_COLS = df.columns.tolist()\n",
        "FEATURE_COLS = [col for col in ALL_COLS if col not in COLUMNS_TO_DROP and col != TARGET_VARIABLE]\n",
        "\n",
        "NUMERIC_FEATURES = df[FEATURE_COLS].select_dtypes(include=['float64']).columns.tolist()\n",
        "CATEGORICAL_FEATURES = df[FEATURE_COLS].select_dtypes(include=['object', 'bool', 'int32', 'int64']).columns.tolist()\n",
        "\n",
        "existing_cols_to_drop = [col for col in COLUMNS_TO_DROP if col in df.columns]\n",
        "df_processed = df.drop(columns=existing_cols_to_drop)\n",
        "\n",
        "y = df_processed[TARGET_VARIABLE]\n",
        "X = df_processed.drop(columns=[TARGET_VARIABLE])\n",
        "\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "print(f\"Clases del objetivo: {list(le.classes_)}\")\n",
        "\n",
        "numeric_features = X[NUMERIC_FEATURES].columns.tolist()\n",
        "categorical_features = X[CATEGORICAL_FEATURES].columns.tolist()\n",
        "\n",
        "print(f\"Características numéricas ({len(numeric_features)}): {numeric_features}\")\n",
        "print(f\"Características categóricas ({len(categorical_features)}): {categorical_features}\")\n",
        "\n",
        "for col in categorical_features:\n",
        "    X[col] = LabelEncoder().fit_transform(X[col])    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "bbc54ef5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Split train/test estratificado ---\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.3, random_state=42, stratify=y_encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "66494fbe",
      "metadata": {},
      "outputs": [],
      "source": [
        "# # --- Seleccionar columnas categóricas para One-Hot ---\n",
        "# encoder = OneHotEncoder(sparse_output=False, drop='first', handle_unknown='ignore')\n",
        "\n",
        "# cat_cols = [\n",
        "#     col for col in df[FEATURE_COLS].select_dtypes(include=['object', 'int32', 'int64']).columns\n",
        "#     if col in X_train.columns and (\n",
        "#         X_train[col].nunique() > 2 or\n",
        "#         (X_train[col].nunique() == 2 and set(X_train[col].dropna().unique()) != {0, 1})\n",
        "#     )\n",
        "# ]\n",
        "\n",
        "# binary_cat_cols = [col for col in X_train.columns if col not in cat_cols and X_train[col].nunique() == 2]\n",
        "\n",
        "# # --- One-Hot encode -----------------------------------------------------\n",
        "# X_train_encoded_cat = pd.DataFrame(\n",
        "#     encoder.fit_transform(X_train[cat_cols]),\n",
        "#     columns=encoder.get_feature_names_out(cat_cols),\n",
        "#     index=X_train.index\n",
        "# )\n",
        "\n",
        "# X_test_encoded_cat = pd.DataFrame(\n",
        "#     encoder.transform(X_test[cat_cols]),\n",
        "#     columns=encoder.get_feature_names_out(cat_cols),\n",
        "#     index=X_test.index\n",
        "# )\n",
        "\n",
        "# processed_cat_columns = X_train_encoded_cat.columns.tolist() + binary_cat_cols\n",
        "\n",
        "# X_train_categorical = pd.concat([X_train[binary_cat_cols], X_train_encoded_cat], axis=1)\n",
        "# X_test_categorical = pd.concat([X_test[binary_cat_cols], X_test_encoded_cat], axis=1)\n",
        "\n",
        "processed_cat_columns = CATEGORICAL_FEATURES.copy()\n",
        "\n",
        "X_train_categorical = X_train[processed_cat_columns].copy()\n",
        "X_test_categorical = X_test[processed_cat_columns].copy()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "fb1e39a7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Archivos guardados con StandardScaler\n",
            "train_std_main_financial_metrics.csv\n",
            "test_std_main_financial_metrics.csv\n",
            "✅ Archivos guardados con MinMaxScaler\n",
            "train_minmax_main_financial_metrics.csv\n",
            "test_minmax_main_financial_metrics.csv\n"
          ]
        }
      ],
      "source": [
        "# --- STANDARD SCALER -----------------------------------------------------\n",
        "scaler_std = StandardScaler()\n",
        "X_train_scaled_num = pd.DataFrame(\n",
        "    scaler_std.fit_transform(X_train[numeric_features]),\n",
        "    columns=numeric_features,\n",
        "    index=X_train.index\n",
        ")\n",
        "X_test_scaled_num = pd.DataFrame(\n",
        "    scaler_std.transform(X_test[numeric_features]),\n",
        "    columns=numeric_features,\n",
        "    index=X_test.index\n",
        ")\n",
        "\n",
        "# Combinar numéricas, binarias y One-Hot\n",
        "X_train_std_final = pd.concat([X_train_scaled_num, X_train_categorical], axis=1)\n",
        "X_test_std_final = pd.concat([X_test_scaled_num, X_test_categorical], axis=1)\n",
        "\n",
        "# Añadir target\n",
        "train_std_final = X_train_std_final.copy()\n",
        "test_std_final = X_test_std_final.copy()\n",
        "train_std_final[\"target\"] = y_train\n",
        "test_std_final[\"target\"] = y_test\n",
        "\n",
        "# Guardar CSV StandardScaler\n",
        "train_std_final.to_csv(\"train_std_main_financial_metrics.csv\", index=False)\n",
        "test_std_final.to_csv(\"test_std_main_financial_metrics.csv\", index=False)\n",
        "\n",
        "print(\"✅ Archivos guardados con StandardScaler\")\n",
        "print(\"train_std_main_financial_metrics.csv\")\n",
        "print(\"test_std_main_financial_metrics.csv\")\n",
        "\n",
        "# --- MIN-MAX SCALER ------------------------------------------------------\n",
        "scaler_minmax = MinMaxScaler()\n",
        "X_train_minmax_num = pd.DataFrame(\n",
        "    scaler_minmax.fit_transform(X_train[numeric_features]),\n",
        "    columns=numeric_features,\n",
        "    index=X_train.index\n",
        ")\n",
        "\n",
        "X_test_minmax_num = pd.DataFrame(\n",
        "    scaler_minmax.transform(X_test[numeric_features]),\n",
        "    columns=numeric_features,\n",
        "    index=X_test.index\n",
        ")\n",
        "\n",
        "# Combinar numéricas, binarias y One-Hot\n",
        "X_train_minmax_final = pd.concat([X_train_minmax_num, X_train_categorical], axis=1)\n",
        "X_test_minmax_final = pd.concat([X_test_minmax_num, X_test_categorical], axis=1)\n",
        "\n",
        "# Añadir target\n",
        "train_minmax_final = X_train_minmax_final.copy()\n",
        "test_minmax_final = X_test_minmax_final.copy()\n",
        "train_minmax_final[\"target\"] = y_train\n",
        "test_minmax_final[\"target\"] = y_test\n",
        "\n",
        "# Guardar CSV MinMaxScaler\n",
        "train_minmax_final.to_csv(\"train_minmax_main_financial_metrics.csv\", index=False)\n",
        "test_minmax_final.to_csv(\"test_minmax_main_financial_metrics.csv\", index=False)\n",
        "\n",
        "print(\"✅ Archivos guardados con MinMaxScaler\")\n",
        "print(\"train_minmax_main_financial_metrics.csv\")\n",
        "print(\"test_minmax_main_financial_metrics.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "3fc5819d",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "target",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "count",
                  "rawType": "int64",
                  "type": "integer"
                }
              ],
              "ref": "339d71d8-d836-4477-bc14-040d1f2bfe36",
              "rows": [
                [
                  "2",
                  "317"
                ],
                [
                  "0",
                  "317"
                ],
                [
                  "3",
                  "317"
                ],
                [
                  "4",
                  "317"
                ],
                [
                  "1",
                  "317"
                ]
              ],
              "shape": {
                "columns": 1,
                "rows": 5
              }
            },
            "text/plain": [
              "target\n",
              "2    317\n",
              "0    317\n",
              "3    317\n",
              "4    317\n",
              "1    317\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Train reequilibrado con SMOTE guardado: train_std_balanced.csv\n"
          ]
        }
      ],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# --- SMOTE sobre train (solo StandardScaler como ejemplo) ---\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_balanced, y_train_balanced = smote.fit_resample(\n",
        "    train_std_final.drop(columns=[\"target\"]),\n",
        "    train_std_final[\"target\"]\n",
        ")\n",
        "\n",
        "train_balanced_df = X_train_balanced.copy()\n",
        "train_balanced_df[\"target\"] = y_train_balanced\n",
        "\n",
        "# Guardar CSV reequilibrado\n",
        "display(train_balanced_df[\"target\"].value_counts())\n",
        "train_balanced_df.to_csv(\"train_std_balanced.csv\", index=False)\n",
        "print(\"✅ Train reequilibrado con SMOTE guardado: train_std_balanced.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "1af4fce7",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Definir conjuntos finales para modelado. Esta vez usaré std scaler\n",
        "X_train = X_train_std_final.copy()\n",
        "X_test = X_test_std_final.copy()\n",
        "y_train = train_std_final['target'].copy()\n",
        "y_test = test_std_final['target'].copy()\n",
        "\n",
        "\n",
        "# Eliminar variables del namespace\n",
        "del X_train_std_final, X_test_std_final\n",
        "del X_train_minmax_final, X_test_minmax_final\n",
        "del train_std_final, test_std_final\n",
        "del train_minmax_final, test_minmax_final\n",
        "\n",
        "# Forzar recolección de basura\n",
        "import gc\n",
        "gc.collect()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2. Métodos de Filtro (Filter Methods)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.1 Métodos Paramétricos\n",
        "\n",
        "### Predictores Continuos: ANOVA (t-test)\n",
        "`f_classif` de Scikit-learn implementa un test F de ANOVA. Si el problema es de clasificación binaria, esto es equivalente a un **t-test**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- 2.1.1 Filter: ANOVA F-test (f_classif) ---\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'K_BEST' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[19], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--- 2.1.1 Filter: ANOVA F-test (f_classif) ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m selector_anova \u001b[38;5;241m=\u001b[39m SelectKBest(score_func\u001b[38;5;241m=\u001b[39mf_classif, k\u001b[38;5;241m=\u001b[39m\u001b[43mK_BEST\u001b[49m)\n\u001b[0;32m      3\u001b[0m selector_anova\u001b[38;5;241m.\u001b[39mfit(X_train_scaled, y_train)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Obtener resultados\u001b[39;00m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'K_BEST' is not defined"
          ]
        }
      ],
      "source": [
        "print(\"--- 2.1.1 Filter: ANOVA F-test (f_classif) ---\")\n",
        "selector_anova = SelectKBest(score_func=f_classif, k=K_BEST)\n",
        "selector_anova.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Obtener resultados\n",
        "selected_indices_anova = selector_anova.get_support(indices=True)\n",
        "selected_features_anova = X.columns[selected_indices_anova]\n",
        "scores_anova = selector_anova.scores_[selected_indices_anova]\n",
        "\n",
        "results_anova = pd.DataFrame({'Feature': selected_features_anova, 'F-Score': scores_anova}).sort_values(by='F-Score', ascending=False)\n",
        "print(f\"Mejores {K_BEST} características según ANOVA (f_classif):\")\n",
        "print(results_anova)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Predictores Discretos: Chi-cuadrado (Chi-squared) e Información Mutua\n",
        "\n",
        "* **Chi-cuadrado (`chi2`)**: Requiere características no negativas. Usaremos los datos escalados con `MinMaxScaler`.\n",
        "* **Información Mutua (`mutual_info_classif`)**: Es un método potente, técnicamente no paramétrico, pero `sklearn` lo agrupa aquí. No requiere escalado específico, pero funciona mejor con datos discretos o escalados (como MinMax).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- 2.1.2 Filter: Chi-cuadrado (chi2) ---\n",
            "Mejores 10 características según Chi-cuadrado:\n",
            "                       Feature  Chi2-Score\n",
            "1                     In_SP500   37.134766\n",
            "9                 has_benefits   17.621138\n",
            "2                    In_NASDAQ   16.986076\n",
            "5  trailingAnnualDividendYield   14.622993\n",
            "7          shortPercentOfFloat    9.050226\n",
            "3          enterpriseToRevenue    7.740894\n",
            "6       sharesPercentSharesOut    6.459521\n",
            "0      numberOfAnalystOpinions    6.148590\n",
            "8          heldPercentInsiders    5.762688\n",
            "4                    totalDebt    3.063679\n",
            "\n",
            "--- 2.1.3 Filter: Información Mutua (mutual_info_classif) ---\n",
            "Mejores 10 características según Información Mutua:\n",
            "                       Feature  MI-Score\n",
            "1                 52WeekChange  0.079091\n",
            "9          shortPercentOfFloat  0.064126\n",
            "3                revenueGrowth  0.062290\n",
            "7            operatingCashflow  0.060976\n",
            "0                   allTimeLow  0.055693\n",
            "4            netIncomeToCommon  0.055190\n",
            "2               returnOnAssets  0.053952\n",
            "8  trailingAnnualDividendYield  0.053832\n",
            "6                 currentRatio  0.053291\n",
            "5                   quickRatio  0.052149\n"
          ]
        }
      ],
      "source": [
        "print(f\"\\n--- 2.1.2 Filter: Chi-cuadrado (chi2) ---\")\n",
        "# Usamos X_train_minmax (no negativos)\n",
        "selector_chi2 = SelectKBest(score_func=chi2, k=K_BEST)\n",
        "selector_chi2.fit(X_train_minmax, y_train)\n",
        "\n",
        "# Obtener resultados\n",
        "selected_indices_chi2 = selector_chi2.get_support(indices=True)\n",
        "selected_features_chi2 = X.columns[selected_indices_chi2]\n",
        "scores_chi2 = selector_chi2.scores_[selected_indices_chi2]\n",
        "\n",
        "results_chi2 = pd.DataFrame({'Feature': selected_features_chi2, 'Chi2-Score': scores_chi2}).sort_values(by='Chi2-Score', ascending=False)\n",
        "print(f\"Mejores {K_BEST} características según Chi-cuadrado:\")\n",
        "print(results_chi2)\n",
        "\n",
        "print(f\"\\n--- 2.1.3 Filter: Información Mutua (mutual_info_classif) ---\")\n",
        "# Usamos X_train_minmax (buena práctica para MI)\n",
        "selector_mi = SelectKBest(score_func=mutual_info_classif, k=K_BEST)\n",
        "selector_mi.fit(X_train_minmax, y_train)\n",
        "\n",
        "# Obtener resultados\n",
        "selected_indices_mi = selector_mi.get_support(indices=True)\n",
        "selected_features_mi = X.columns[selected_indices_mi]\n",
        "scores_mi = selector_mi.scores_[selected_indices_mi]\n",
        "\n",
        "results_mi = pd.DataFrame({'Feature': selected_features_mi, 'MI-Score': scores_mi}).sort_values(by='MI-Score', ascending=False)\n",
        "print(f\"Mejores {K_BEST} características según Información Mutua:\")\n",
        "print(results_mi)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Métodos Paramétricos (No implementados en `sklearn`)\n",
        "* **Gain ratio, Symmetrical uncertainty, Odds ratio, Bi-normal separation**: Estos métodos no están disponibles en `scikit-learn` y requerirían implementaciones manuales o librerías de terceros (ej. `skfeature`).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.2 Métodos No Paramétricos (Model-Free)\n",
        "\n",
        "### Mann-Whitney y Kruskal-Wallis\n",
        "Son las alternativas no paramétricas al t-test y ANOVA, respectivamente. Se usan cuando no se asume una distribución normal. Los aplicaremos desde `scipy.stats`.\n",
        "\n",
        "* **Mann-Whitney U test**: Para 2 clases.\n",
        "* **Kruskal-Wallis H test**: Para 2 o más clases.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- 2.2.1 Filter: Kruskal-Wallis / Mann-Whitney ---\n",
            "Aplicando Kruskal-Wallis H test (5 clases)\n",
            "Mejores 10 características según el test No Paramétrico (p-value más bajo):\n",
            "                        Feature       p-value\n",
            "19                revenueGrowth  3.354177e-20\n",
            "22                 grossProfits  1.386005e-17\n",
            "32            operatingCashflow  3.716922e-16\n",
            "20                 totalRevenue  8.791060e-16\n",
            "23                       ebitda  3.767622e-15\n",
            "28                    totalDebt  2.398883e-14\n",
            "34  trailingAnnualDividendYield  5.887412e-13\n",
            "10              enterpriseValue  6.776325e-13\n",
            "4                  52WeekChange  1.802058e-12\n",
            "41          shortPercentOfFloat  1.981951e-12\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n--- 2.2.1 Filter: Kruskal-Wallis / Mann-Whitney ---\")\n",
        "# Usamos los datos originales (no escalados), ya que estos tests se basan en rangos.\n",
        "n_classes = len(np.unique(y_train))\n",
        "p_values = []\n",
        "feature_names = X_train.columns\n",
        "\n",
        "if n_classes == 2:\n",
        "    print(\"Aplicando Mann-Whitney U test (2 clases)\")\n",
        "    group1 = X_train[y_train == 0]\n",
        "    group2 = X_train[y_train == 1]\n",
        "    for col in feature_names:\n",
        "        # Añadimos 'alternative='two-sided'' para compatibilidad con scipy moderno\n",
        "        try:\n",
        "            stat, p = mannwhitneyu(group1[col], group2[col], alternative='two-sided')\n",
        "            p_values.append(p)\n",
        "        except ValueError:\n",
        "            p_values.append(1.0) # Asignar p-value alto si hay error (ej. varianza cero)\n",
        "else:\n",
        "    print(f\"Aplicando Kruskal-Wallis H test ({n_classes} clases)\")\n",
        "    groups = [X_train[y_train == i] for i in np.unique(y_train)]\n",
        "    for i, col in enumerate(feature_names):\n",
        "        samples = [g.iloc[:, i] for g in groups]\n",
        "        try:\n",
        "            stat, p = kruskal(*samples)\n",
        "            p_values.append(p)\n",
        "        except ValueError:\n",
        "            p_values.append(1.0)\n",
        "\n",
        "# Un p-value más bajo significa que la característica es más discriminativa\n",
        "results_nonparam = pd.DataFrame({'Feature': feature_names, 'p-value': p_values}).sort_values(by='p-value', ascending=True)\n",
        "print(f\"Mejores {K_BEST} características según el test No Paramétrico (p-value más bajo):\")\n",
        "print(results_nonparam.head(K_BEST))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Métodos No Paramétricos (No implementados en `sklearn`)\n",
        "* **Threshold number of misclassification (TNoM)**\n",
        "* **P-metric**\n",
        "* **Between-groups to within-groups sum of squares** (Relacionado con ANOVA, pero implementaciones específicas pueden variar)\n",
        "* **Scores based on estimating density functions**\n",
        "\n",
        "Estos son métodos especializados que requieren implementación manual.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 4. Métodos Wrapper (Wrapper Methods)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9a59c05",
      "metadata": {},
      "source": [
        "## 4.0 Definición de Modelos No Probabilísticos\n",
        "\n",
        "Estos son los modelos que se utilizarán como evaluadores en los métodos Wrapper.\n",
        "* k-nearest neighbors (KNN)\n",
        "* Classification trees (Decision Tree)\n",
        "* Artificial neural networks (ANN / MLP)\n",
        "* Support vector machines (SVM)\n",
        "* Rule induction (No existe en sklearn, usaremos `DecisionTreeClassifier` como la aproximación más cercana).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c34d21d5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Modelos base definidos.\n"
          ]
        }
      ],
      "source": [
        "# K-Features a seleccionar (para los ejemplos)\n",
        "K_BEST = 10 \n",
        "\n",
        "# Diccionario de modelos\n",
        "# Usamos configuraciones más simples para que los wrappers se ejecuten más rápido\n",
        "models = {\n",
        "    \"DecisionTree\": DecisionTreeClassifier(random_state=42),\n",
        "    \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
        "    \"SVM (Linear)\": SVC(kernel='linear', random_state=42, probability=False), # Kernel lineal es más rápido\n",
        "    \"ANN (MLP)\": MLPClassifier(hidden_layer_sizes=(50,), max_iter=300, random_state=42) # Red pequeña\n",
        "}\n",
        "\n",
        "print(\"Modelos base definidos.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4.1 Heurísticas Determinísticas\n",
        "\n",
        "### Métodos Secuenciales (SFS y SBE)\n",
        "`SequentialFeatureSelector` de Scikit-learn (SFS) puede operar en ambas direcciones:\n",
        "* **Sequential Forward Selection (`direction='forward'`)**: Empieza sin características y añade la mejor en cada paso.\n",
        "* **Sequential Backward Elimination (`direction='backward'`)**: Empieza con todas las características y elimina la peor en cada paso.\n",
        "\n",
        "**Nota:** Estos métodos son *muy* lentos. Usaremos un modelo rápido (`DecisionTree`) y un número bajo de características a seleccionar (`K_WRAPPER = 5`) para este ejemplo.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- 4.1.1 Wrapper: Sequential Methods ---\n",
            "Iniciando Sequential Forward Selection (SFS) para 5 features...\n",
            "Modelo: DecisionTree, Métrica: accuracy\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n--- 4.1.1 Wrapper: Sequential Methods ---\")\n",
        "K_WRAPPER = 5 # Usar un K pequeño, SBE es muy costoso\n",
        "model_wrapper = models[\"DecisionTree\"]\n",
        "# Usamos datos escalados (X_train_scaled) ya que los modelos (excepto DT) lo prefieren.\n",
        "# Aunque DT es invariante, es buena práctica mantener consistencia.\n",
        "scoring_metric = 'accuracy' # Métrica para evaluar\n",
        "\n",
        "# --- SFS ---\n",
        "print(f\"Iniciando Sequential Forward Selection (SFS) para {K_WRAPPER} features...\")\n",
        "print(f\"Modelo: DecisionTree, Métrica: {scoring_metric}\")\n",
        "sfs = SequentialFeatureSelector(\n",
        "    model_wrapper,\n",
        "    n_features_to_select=K_WRAPPER,\n",
        "    direction='forward',\n",
        "    scoring=scoring_metric,\n",
        "    cv=3, # 3-fold cross-validation\n",
        "    n_jobs=-1 # Usar todos los cores\n",
        ")\n",
        "\n",
        "start_time = time.time()\n",
        "sfs.fit(X_train_scaled, y_train)\n",
        "end_time = time.time()\n",
        "\n",
        "selected_indices_sfs = sfs.get_support(indices=True)\n",
        "selected_features_sfs = X.columns[selected_indices_sfs]\n",
        "\n",
        "print(f\"SFS completado en {end_time - start_time:.2f} segundos.\")\n",
        "print(f\"Características seleccionadas (SFS): {list(selected_features_sfs)}\")\n",
        "\n",
        "# --- SBE ---\n",
        "print(f\"\\nIniciando Sequential Backward Elimination (SBE) para {K_WRAPPER} features...\")\n",
        "print(f\"Modelo: DecisionTree, Métrica: {scoring_metric}\")\n",
        "sbe = SequentialFeatureSelector(\n",
        "    model_wrapper,\n",
        "    n_features_to_select=K_WRAPPER,\n",
        "    direction='backward',\n",
        "    scoring=scoring_metric,\n",
        "    cv=3,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "start_time = time.time()\n",
        "sbe.fit(X_train_scaled, y_train)\n",
        "end_time = time.time()\n",
        "\n",
        "selected_indices_sbe = sbe.get_support(indices=True)\n",
        "selected_features_sbe = X.columns[selected_indices_sbe]\n",
        "\n",
        "print(f\"SBE completado en {end_time - start_time:.2f} segundos.\")\n",
        "print(f\"Características seleccionadas (SBE): {list(selected_features_sbe)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Métodos Determinísticos (No implementados en `sklearn`)\n",
        "* **Greedy hill climbing / Best first**: SFS y SBE son las implementaciones más comunes de estas estrategias.\n",
        "* **Plus-L-Minus-r algorithm, Floating search selection (SFFS/SBFS)**: Son variaciones más avanzadas. La librería `mlxtend` (no disponible aquí) implementa SFFS y SBFS.\n",
        "* **Tabu search, Branch and bound**: Son algoritmos de optimización global muy complejos, no estándar para feature selection en `sklearn`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4.2 Heurísticas No Determinísticas (Metaheurísticas)\n",
        "\n",
        "Esta categoría incluye todos los algoritmos estocásticos (basados en aleatoriedad) y poblacionales.\n",
        "* **Single-Solution**: Simulated annealing, Las Vegas, GRASP, Variable neighborhood search.\n",
        "* **Population-Based**: Scatter search, Ant colony optimization (ACO), Particle swarm optimization (PSO).\n",
        "* **Evolutionary Algorithms**: Genetic algorithms (GA), Estimation of distribution algorithms (EDA), Differential evolution (DE), Genetic programming (GP), Evolution strategies (ES).\n",
        "\n",
        "**Todos estos métodos requieren librerías especializadas** (ej. `DEAP`, `sklearn-genetic`, `pyswarms`, `mealpy`) o implementaciones manuales muy complejas. No están disponibles en `scikit-learn`.\n",
        "\n",
        "A continuación, se muestra un *ejemplo conceptual* de cómo se usaría un Algoritmo Genético si la librería `genetic_selection` estuviera instalada.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n--- 4.2.1 Wrapper: Metaheurísticas (Ejemplo Conceptual) ---\")\n",
        "print(\"Las metaheurísticas (GA, PSO, ACO, etc.) NO están implementadas en scikit-learn.\")\n",
        "print(\"Requieren librerías de terceros como 'sklearn-genetic', 'DEAP', 'pyswarms', etc.\")\n",
        "print(\"A continuación se muestra un bloque de código comentado como ejemplo conceptual.\")\n",
        "\n",
        "# --- Código comentado (NO SE EJECUTA) ---\n",
        "\"\"\"\n",
        "try:\n",
        "    # pip install sklearn-genetic\n",
        "    from genetic_selection import GeneticSelectionCV\n",
        "    \n",
        "    print(\"Librería 'genetic_selection' encontrada. Ejecutando ejemplo de GA...\")\n",
        "    \n",
        "    # Usar un estimador rápido\n",
        "    estimator_ga = models[\"DecisionTree\"]\n",
        "    \n",
        "    selector_ga = GeneticSelectionCV(\n",
        "        estimator_ga,\n",
        "        cv=3,\n",
        "        scoring=\"accuracy\",\n",
        "        population_size=30, # Reducido para el ejemplo\n",
        "        generations=20,     # Reducido para el ejemplo\n",
        "        n_jobs=-1,\n",
        "        verbose=0,\n",
        "        caching=True\n",
        "    )\n",
        "    \n",
        "    # selector_ga.fit(X_train_scaled, y_train)\n",
        "    # selected_features_ga = X.columns[selector_ga.support_]\n",
        "    # print(f\"Características seleccionadas (GA): {list(selected_features_ga)}\")\n",
        "    print(\"Ejecución de GA omitida por tiempo, pero la librería está presente.\")\n",
        "\n",
        "except ImportError:\n",
        "    print(\"Librería 'genetic_selection' no encontrada. Omitiendo ejemplo de GA.\")\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 5. Conclusión"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Este notebook ha implementado los métodos de selección de características más comunes y accesibles de la lista proporcionada, utilizando `scikit-learn` y `scipy`.\n",
        "\n",
        "**Resumen de Métodos Implementados:**\n",
        "* **Filtro (Paramétrico):** ANOVA / t-test (`f_classif`), Chi-cuadrado (`chi2`), Información Mutua (`mutual_info_classif`).\n",
        "* **Filtro (No Paramétrico):** Mann-Whitney y Kruskal-Wallis (de `scipy.stats`).\n",
        "* **Wrapper (Determinístico):** Sequential Forward Selection (SFS) y Sequential Backward Elimination (SBE) (de `sklearn.feature_selection`).\n",
        "\n",
        "Los métodos más avanzados (especialmente los wrappers no determinísticos y los filtros menos comunes) requerirían librerías especializadas o una implementación manual intensiva.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "finan-ml",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
